{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for Traditional RAG approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 00:12:23.129738: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-15 00:12:23.129775: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-15 00:12:23.130623: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-15 00:12:23.855276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from database.GraphDB import KnowledgeGraphDB\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    HuggingFaceEmbeddings,\n",
    ")\n",
    "from agent.llm.llm_utils import *\n",
    "from agent import BedRockLLMs, CoreLLMs, Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = KnowledgeGraphDB(uri=\"bolt://localhost:8687\", user=\"neo4j\", password=\"quanghung2004\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_to_plan_text(data):\n",
    "    id_text = dict()\n",
    "    for doc in data:\n",
    "        id = doc[0].metadata['id']\n",
    "        text = doc[0].page_content\n",
    "        if id not in id_text:\n",
    "            id_text[id] = []\n",
    "        id_text[id].append(text)\n",
    "    \n",
    "    plain_text = ''\n",
    "    for k, v in id_text.items():\n",
    "        plain_text += f'**ID {k}**\\n'\n",
    "        plain_text += ' '.join(v) + '\\n\\n'\n",
    "    \n",
    "    return plain_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RAG(questions, top_k):\n",
    "    data = kg.summary_db.similarity_search_with_relevance_scores(questions,max(20, int(top_k*2)))\n",
    "    return document_to_plan_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = os.getenv('ACCESS_KEY')\n",
    "secret_key = os.getenv('SECRET_KEY') \n",
    "# secret_token = os.getenv('SECRET_TOKEN')\n",
    "model_name_cv = os.getenv('MODEL_NAME_CV')\n",
    "model_name_jd = os.getenv('MODEL_NAME_ROUTING')\n",
    "model_name = os.getenv('MODEL_NAME')\n",
    "region_name = os.getenv('REGION_NAME')\n",
    "llm_jd_extraction_args = {\n",
    "    \"model_name\": model_name_jd,\n",
    "    \"access_key\": access_key,\n",
    "    \"secret_key\": secret_key,\n",
    "    # \"secret_token\": secret_token,\n",
    "    \"region_name\": region_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- tokenization_phi3_small.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ca1a8708b84c1b924f364596fd0dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- configuration_phi3_small.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- positional_embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- triton_flash_blocksparse_attn.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- triton_blocksparse_attention_layer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-small-8k-instruct:\n",
      "- modeling_phi3_small.py\n",
      "- positional_embedding.py\n",
      "- triton_flash_blocksparse_attn.py\n",
      "- triton_blocksparse_attention_layer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a3f6cfaa104736bd70fba7ab4aca95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed15a66c4e047498b39107b89f3708d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# llm = BedRockLLMs(**llm_jd_extraction_args)\n",
    "llm = CoreLLMs(model_name=\"microsoft/Phi-3-small-8k-instruct\")\n",
    "# llm = Gemini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "import numpy as np\n",
    "\n",
    "reranker_model = 'BAAI/bge-reranker-v2-m3'\n",
    "reranker = FlagReranker(reranker_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query(query, docs):\n",
    "    \n",
    "    if isinstance(query, list):\n",
    "        query = query[0]\n",
    "    if isinstance(docs, str):\n",
    "        docs = [docs]\n",
    "        \n",
    "    pairs = []\n",
    "    for doc in docs:\n",
    "        pairs.append([query, doc])\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def rerank(query, docs, k):\n",
    "    pairs = create_query(query, docs)\n",
    "    scores = np.array(reranker.compute_score(pairs))\n",
    "    docs = np.array(docs)\n",
    "    \n",
    "    top_k_indices = np.argpartition(scores, -k)[-k:]\n",
    "    top_k_elements = scores[top_k_indices]\n",
    "    # print(top_k_indices)\n",
    "    \n",
    "    top_k_indices = top_k_indices[np.argsort(-top_k_elements)]\n",
    "    return docs[top_k_indices].tolist()\n",
    "\n",
    "def RAG_rerank(questions, top_k):\n",
    "    data = kg.summary_db.similarity_search(questions,max(int(top_k*3), 30))\n",
    "    pick_doc = rerank(questions, [doc.page_content for doc in data], max(top_k*2,20))\n",
    "    top_doc = []\n",
    "    for doc in data:\n",
    "        if doc.page_content in pick_doc:\n",
    "            top_doc.append((doc,None))\n",
    "    \n",
    "    return document_to_plan_text(top_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(llm, question, top_k):\n",
    "    context = RAG_rerank(question, top_k)\n",
    "\n",
    "    message = f\"\"\"  \n",
    "    You are given a job description and a list of candidates. Your task is to pick the candidate that suitable with the job description.\n",
    "    You must only choose the top candidate that fit with the number of candidates required.\n",
    "    **Job Description**\n",
    "    {question}\n",
    "    \n",
    "    **Candidates**\n",
    "    {context}\n",
    "    \n",
    "    Return the chosen candidate in JSON format:\n",
    "    ```json\n",
    "    [\n",
    "        {{\n",
    "            \"candidate_id\": [1, 2, 3, 4, 5, 6]\n",
    "        }}\n",
    "    ]\n",
    "    ```\n",
    "    The order of the list is the ranking of the candidates.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\"content\":\"You are a helpful assistant for HR department. The current recruitment date is May 2024\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = llm(messages)\n",
    "    ids = get_json_from_text_response(response)[0][\"candidate_id\"]\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    MATCH (c:Application)\n",
    "    WHERE id(c) IN {ids}\n",
    "    RETURN c.file as file\n",
    "    \"\"\"\n",
    "    files = kg.query(query)\n",
    "    files = [f['file'].split('/')[-1] for f in files]\n",
    "    return files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = \"Find 2 candidate having around 2-4 years of experience as Back-end Development\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quanghung20gg/.cache/huggingface/modules/transformers_modules/microsoft/Phi-3-small-8k-instruct/69caae1f2acea34b26f535fecb1f2abb9a304695/triton_flash_blocksparse_attn.py:88: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  x = [xi.to_sparse_csr() for xi in x]\n"
     ]
    }
   ],
   "source": [
    "res = evaluate_pipeline(llm, questions, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TranVanDanTruong-CV-BackEndDeveloper.pdf', 'CV TRAN TUAN KIET - NodeJs-TopCV.vn (2).pdf', 'DANG_TRUONG_SON.pdf', 'NguyenTienPhat_CV_Backend_Developer.pdf', 'HUYNH-TRUNG-NGHIA-CV-EN-2024.pdf', 'Nguyen Xuan Giang CV.pdf']\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "questions = json.loads(open('data/benchmark/qa_cv.json', 'r', encoding='utf-8').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 9/39 [00:24<01:08,  2.27s/it]--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/logging/__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/logging/__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_46111/887611918.py\", line 10, in <module>\n",
      "    res = evaluate_pipeline(llm, prompt, len(question['answer']))\n",
      "  File \"/tmp/ipykernel_46111/2371494929.py\", line 33, in evaluate_pipeline\n",
      "    response = llm(messages)\n",
      "  File \"/home/quanghung20gg/Documents/hung20gg/cv_rank/agent/llm/llm.py\", line 81, in __call__\n",
      "    return self.pipe(message, **self.generation_args)[0]['generated_text'][-1]['content']\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/transformers/pipelines/text_generation.py\", line 235, in __call__\n",
      "    return super().__call__(Chat(text_inputs), **kwargs)\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/home/quanghung20gg/anaconda3/lib/python3.11/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n",
      " 51%|█████▏    | 20/39 [00:54<00:54,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No JSON response found in text response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:41<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "i = 0\n",
    "from tqdm import tqdm\n",
    "for question in tqdm(questions):\n",
    "    prompt = question['prompt']\n",
    "    answer = dict()\n",
    "    answer['prompt'] = prompt\n",
    "    answer['answer'] = question['answer']\n",
    "    try:\n",
    "        res = evaluate_pipeline(llm, prompt, len(question['answer']))\n",
    "        answer['predict'] = res\n",
    "    except:\n",
    "        answer['predict'] = []\n",
    "    answers.append(answer)\n",
    "    with open('qa_cv_result_rerank.json', 'w') as f:\n",
    "        f.write(json.dumps(answers))\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prompt': 'Find 12 Marketers in Ha Noi', 'answer': ['Portfolio - Nguyen Tien Dat.pdf', 'Nguyễn-Hoàng-Việt-Content.pdf', 'CV_TRẦN THỊ HẢI YẾN - Hải Yến Trần.pdf', 'CV123.pdf', 'Intern Digital MKT_Nguyen Thi Mai Huong.pdf', 'LuongTienHuy-resume.pdf', 'CV Thiên Khôi - Duyên Nguyễn.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf', 'CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf', 'CV-Le Nhat Linh.pdf', 'Digital Marketing Resume-Nguyen Thanh Tuyen.pdf', 'NGUYEN-THI-THANH-HANG-CV - Marketing Executive.pdf'], 'predict': ['Nguyen-Thi-Van-Anh (1).pdf']}, {'prompt': 'Find 5 Marketers in Ho Chi Minh City', 'answer': ['CV - Nguyễn Thị Kiều Oanh .pdf', 'TTS MARKETING - BÙI VĨNH HUY (1).pdf', 'CV Content Creator.pdf', 'Phi Ha Nhi_Brand Marketing Exe_Strategic Planner.pdf', 'CV Marketing Executive - Le Thi Thuy Trang.pdf'], 'predict': ['Nguyen-Thi-Van-Anh (1).pdf', 'Phi Ha Nhi_Brand Marketing Exe_Strategic Planner.pdf', 'CV-Le Nhat Linh.pdf', 'CV123.pdf', 'Quách Thụy Kim Ngân -- Nhân viên thu mua.pdf']}, {'prompt': 'Find 7 Applications for marketing intern position', 'answer': ['BAupdatedCV.ngocluu.pdf', 'TTS MARKETING - BÙI VĨNH HUY (1).pdf', 'CV_TRẦN THỊ HẢI YẾN - Hải Yến Trần.pdf', 'Intern Digital MKT_Nguyen Thi Mai Huong.pdf', 'LuongTienHuy-resume.pdf', 'CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf'], 'predict': ['Nhan_Nguyen_Resume_Updated.pdf', 'Digital Marketing Resume-Nguyen Thanh Tuyen.pdf', 'NGUYEN-THI-THANH-HANG-CV - Marketing Executive.pdf', 'interview-web-resume.pdf', 'CV - Nguyễn Thị Kiều Oanh .pdf', 'Nguyễn-Hoàng-Việt-Content.pdf']}, {'prompt': 'Find 2 Odoo Developer', 'answer': ['CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'cv_odoo_fresher.pdf'], 'predict': ['Resume_BE_Nguyen Thanh Liem.pdf', 'CV_Trần Văn Đạt.pdf', 'cv-Duy-new.pdf', 'CV_Nguyen_Le_Van_Khai.pdf', 'CV_Nguyễn duy lộc.pdf', 'INTERN BACKEND JAVA.pdf']}, {'prompt': 'Find 5 Marketers who is currently studying or graduated from National Economics University', 'answer': ['CV_TRẦN THỊ HẢI YẾN - Hải Yến Trần.pdf', 'CV Thiên Khôi - Duyên Nguyễn.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf', 'CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf', 'CV-Le Nhat Linh.pdf'], 'predict': ['CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf']}, {'prompt': 'Find 11 Applications who suitable for Fresher Data Scientist position', 'answer': ['Thiều Ngọc Mai _CV.pdf', 'Ho Thi Minh Ngan_CV.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'Duy Anh (Jude) Tran - Curriculum Vitae.pdf', '1685351692698.pdf', '1705460581859.pdf', 'TranHoanDucDuy_DataEngineer (1).pdf', 'Vong Vinh Phu - Data.pdf', 'CV ca nhan_Nguyen Cam Ly.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'PhamTienSon_Resume.pdf'], 'predict': ['Thiều Ngọc Mai _CV.pdf', 'CV_SonBao_DS.pdf', 'CV ca nhan_Nguyen Cam Ly.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'NguyenThanhHung_Intern-Fresher_DataEngineer.pdf']}, {'prompt': 'Find 5 candidates who are currently studying or graduated from Hanoi University of Industry', 'answer': ['CV_ĐinhVănThi_Android_Intern.pdf', 'Nguyen-Van-Dong_CV.pdf', 'NguyenVanNam_CV.pdf', 'LuongTienHuy-resume.pdf', 'NguyenTienAnh_InternJavaWeb.pdf'], 'predict': ['CV_ĐinhVănThi_Android_Intern.pdf', 'InternFrontEnd_HoDucPhap.pdf', '1706358876276.pdf', 'CV_Tran Thanh Huyen_2024.pdf', 'Nghia_TTS.pdf']}, {'prompt': 'Find 3 applications for auditing position for EY', 'answer': ['CV - Lý V_nh H_ng 2024.pdf', 'CV NguyenThuTrang - Internal Auditor - English - v2.pdf', 'CV_Vũ Thu Hiền.pdf'], 'predict': ['CV - Lý V_nh H_ng 2024.pdf', 'RileyNelsonResume.pdf', 'Doan-Van-Nhu-Thuat-TopCV.vn-240124.171030.pdf']}, {'prompt': 'Find 2 applications for accounting position for KPMG', 'answer': ['RileyNelsonResume.pdf', 'CV Nguy_n Th_ L_ Xuân - Nhân Viên K_ Toán.pdf', 'CV_Le Dang Thinh.pdf'], 'predict': ['CV - Lý V_nh H_ng 2024.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf']}, {'prompt': 'Find 1 application for internship in human resource', 'answer': ['Le-Thi-Hai-Yen-250324.201747 - Yến Lê.pdf'], 'predict': []}, {'prompt': 'Find 9 applications suitable for Data Analyst or Data Scientist. The candidate must be studied in National Economics University', 'answer': ['cncnmai.pdf', 'Ho Thi Minh Ngan_CV.pdf', 'BuiQuocAnh_Resume.pdf', 'CV_Light_Theme.pdf', 'latest_cv.pdf', 'CV ca nhan_Nguyen Cam Ly.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'Thiều Ngọc Mai _CV.pdf', 'Phuong_Anh_Trinh_CV_CinnamonAI.pdf'], 'predict': ['Thiều Ngọc Mai _CV.pdf', 'CV_Light_Theme.pdf', 'CV ca nhan_Nguyen Cam Ly.pdf', 'CV_HuynhAnhKiet_DataScientist.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'Cream Black Vintage Typographic Social Media Manager Minimalist Resume.pdf']}, {'prompt': 'Find 11 candidates who studied or currently studying in either FPT College or FPT university in Ha Noi', 'answer': ['[FU] CV Intern Java - Python Nguyen Thanh Dat  (1).pdf', 'CV DƯƠNG THANH TÙNG - PH30319.pdf', 'CV Nguyen Dinh dung - CV Intern.Net-TopCV.vn.pdf', 'CV Nguyễn Văn Hải - TTS Mobile.pdf', 'INTERN BACKEND JAVA.pdf', 'NGUYEN-ANH-TUAN-JAVA-INTERN.pdf', 'CV_Trần Văn Đạt.pdf', 'CV INTERN ADR.pdf', 'CV NGUYEN CONG TRANG - thực tập sinh php.pdf', 'Nguyen-Minh-Duc-TopCV.vn-180524.133945.pdf', 'NGUYEN-THI-THANH-HANG-CV - Marketing Executive.pdf'], 'predict': ['DuyLeNguyenMinh_DataEngineer (1).pdf', 'CV DƯƠNG THANH TÙNG - PH30319.pdf', 'CV_SoftwareEngineer_ChienNguyenQuang.pdf', 'CV_Nguyễn duy lộc.pdf', 'DANG_TRUONG_SON.pdf', 'CV_Trần Văn Đạt.pdf']}, {'prompt': 'Find 3 application who had have experience or currently a Marketing Manager', 'answer': ['Nguyen-Thi-Van-Anh (1).pdf', 'Vu-Thi-Hanpdf.pdf', 'Nguyen Quoc Huy CV_MKT Based.pdf'], 'predict': ['Vu-Thi-Hanpdf.pdf', 'Nguyen-Thi-Van-Anh (1).pdf', 'Nguyen Quoc Huy CV_MKT Based.pdf']}, {'prompt': 'Find 3 applications suitable for Data Engineer. The candidate must be studied or currently studying in National Economics University', 'answer': ['Cream Black Vintage Typographic Social Media Manager Minimalist Resume.pdf', 'latest_cv.pdf', 'Nghia_TTS.pdf'], 'predict': ['Cream Black Vintage Typographic Social Media Manager Minimalist Resume.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'CV_Light_Theme.pdf']}, {'prompt': 'Find 2 candidate having around 2-4 years of experience as Back-end Development', 'answer': ['Resume_BE_Nguyen Thanh Liem.pdf', 'TranVanDanTruong-CV-BackEndDeveloper.pdf'], 'predict': ['TranVanDanTruong-CV-BackEndDeveloper.pdf', 'CV TRAN TUAN KIET - NodeJs-TopCV.vn (2).pdf', 'DANG_TRUONG_SON.pdf', 'NguyenTienPhat_CV_Backend_Developer.pdf', 'HUYNH-TRUNG-NGHIA-CV-EN-2024 (1).pdf', 'Nguyen Xuan Giang CV.pdf']}, {'prompt': 'Find 4 candidates who are currently studying or graduated in Ho Chi Minh City University of Industry and Trade', 'answer': ['Le-Thanh-Tan-CV.pdf', 'LE-THANH-TAN-PHP.pdf', 'CV_English_PhanTaiThang_IT Support.pdf', 'CV_HoNguyenThiMyAnh_devPHP (1).pdf'], 'predict': ['InternFrontEnd_HoDucPhap.pdf', 'TranNamPhuong_InternEmbeddedDeveloper.pdf', 'Cv_ LucHuynhTanHoang.pdf', 'CV_Ngo_Hung_Thinh.pdf']}, {'prompt': 'Find 5 candidates who are currently studying or graduated in Ho Chi Minh Open University', 'answer': ['Cv_ LucHuynhTanHoang.pdf', 'CV_Internship_Software_Developer_PhamHoangAn.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'CV Cap Tan Dat - Fresher Flutter Developer.pdf', 'CV xin vi_c ch_nh s_a m_i nh_t.pdf'], 'predict': ['Cv_ LucHuynhTanHoang.pdf', 'CV_Internship_Software_Developer_PhamHoangAn.pdf', 'CV xin vi_c ch_nh s_a m_i nh_t.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'CV Content Creator.pdf']}, {'prompt': 'I am looking for 5 fresher DA/BA', 'answer': ['Cv_ LucHuynhTanHoang.pdf', 'Cv-PhanCaoVu-DA_DE.pdf', 'Ho Thi Minh Ngan_CV.pdf', 'CV_Đức Thành.pdf', 'NGUYENTHILECHI_DATA ANALYST.pdf'], 'predict': ['LTT.pdf', 'PhanDucSung_CV.pdf', 'CV Content Creator.pdf', 'LuongTienHuy-resume.pdf', 'Resume - Nguyen Dang.pdf']}, {'prompt': 'Find 2 Embedded Developer', 'answer': ['TranNamPhuong_InternEmbeddedDeveloper.pdf', 'Trần Tuấn Anh - CV_Embedded Fresher (1).pdf'], 'predict': ['TranNamPhuong_InternEmbeddedDeveloper.pdf', 'HCM_Intern Tester.pdf']}, {'prompt': 'Find 2 It Support', 'answer': ['CV_English_PhanTaiThang_IT Support.pdf', 'ITSupport.CV.pdf'], 'predict': []}, {'prompt': 'We are looking for Mobile Developer in Ha Noi', 'answer': ['CV Nguyễn Văn Hải - TTS Mobile.pdf', 'CV_ĐinhVănThi_Android_Intern.pdf', 'CV INTERN ADR.pdf'], 'predict': ['CV Nguyễn Văn Hải - TTS Mobile.pdf']}, {'prompt': 'Viettel is looking for 6 candidates who are currently studying or graduated in Hanoi University of Science and Technology', 'answer': ['1685351692698.pdf', '1706358876276.pdf', 'TranPhiHungResume.pdf', 'PhamTienSon_Resume.pdf', 'Nghia_TTS.pdf', 'Trần Tuấn Anh - CV_Embedded Fresher (1).pdf'], 'predict': ['CV_HoNguyenThiMyAnh_devPHP (1).pdf']}, {'prompt': 'Find 5 applications come from Ho Chi Minh City and suitable for intern/fresher backend developer', 'answer': ['CV_INTERN BACKEND_NGUYỄN VĂN BỀN.pdf', 'CV_Internship_Software_Developer_PhamHoangAn.pdf', 'Intern-Fresher-Backend-NguyenVanTuan-0835666356.pdf', 'NCV - Intern BE.pdf', 'HUYNH-TRUNG-NGHIA-CV-EN-2024.pdf'], 'predict': ['HUYNH-TRUNG-NGHIA-CV-EN-2024 (1).pdf', 'cv.pdf', 'NodeFlair_Resume_BackendNodejs.pdf', 'Nguyen-Van-Dong_CV.pdf', 'CV TRAN TUAN KIET - NodeJs-TopCV.vn (2).pdf']}, {'prompt': 'Find 4 Senior Developer. Can be any IT-related position', 'answer': ['CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'Nguyen-Van-Nguyen-Developer0082022.pdf', 'Resume_BE_Nguyen Thanh Liem.pdf', 'Resume.pdf'], 'predict': ['Resume_BE_Nguyen Thanh Liem.pdf', 'CV - Nghiêm Xuân __t - DevOps Engineer.pdf', 'Le_Minh_Vuong_CV.pdf', 'Le-Van-Hung-JAVA-CV.pdf']}, {'prompt': 'Find 3 candidate having at least 1 year of experience in DevOps', 'answer': ['CV_TranDongTri_DevOpsFresher.pdf', 'CV - Nghiêm Xuân __t - DevOps Engineer.pdf', 'Le_Minh_Vuong_CV.pdf'], 'predict': ['CV - Nghiêm Xuân __t - DevOps Engineer.pdf', 'Le_Minh_Vuong_CV.pdf', '1706358876276.pdf']}, {'prompt': 'Find 3 Junior/Middle Web Developer', 'answer': ['CV_HuynhMinhChi_FrontendDeveloper.pdf', 'Daniyar-Chekirov-CV.pdf', 'TranPhiHungResume.pdf'], 'predict': ['CV_BACK_END_DEVELOPERS.pdf', 'NguyenVanNam_CV.pdf', 'CV TRAN TUAN KIET - NodeJs-TopCV.vn (2).pdf']}, {'prompt': 'Find 4 candidates having 1-2 years of experience in Planing/Marketing/Content Creator in Ha Noi', 'answer': ['Portfolio - Nguyen Tien Dat.pdf', 'Nguyễn-Hoàng-Việt-Content.pdf', 'CV Thiên Khôi - Duyên Nguyễn.pdf', 'CV-Le Nhat Linh.pdf'], 'predict': ['Phi Ha Nhi_Brand Marketing Exe_Strategic Planner.pdf', 'Marketing-CV-Nguyen-Thi-Khanh-Linhpdf.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf', 'CV Content Creator.pdf']}, {'prompt': 'Find 3 candidates having 1-2 years of experience in Planing/Marketing/Content Creator in Ho Chi Minh City', 'answer': ['CV Content Creator.pdf', 'Digital Marketing Resume-Nguyen Thanh Tuyen.pdf', 'Phi Ha Nhi_Brand Marketing Exe_Strategic Planner.pdf'], 'predict': ['Phi Ha Nhi_Brand Marketing Exe_Strategic Planner.pdf', 'CV Content Creator.pdf', 'CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf']}, {'prompt': 'MBBank is looking for 25 candidates who are currently studying or graduated in National Economics University', 'answer': ['cncnmai.pdf', 'Ho Thi Minh Ngan_CV.pdf', 'CV  Phạm Thị Loan - CV2-TopCV.vn - Loan Phạm Thị.pdf', 'BuiQuocAnh_Resume.pdf', 'Cream Black Vintage Typographic Social Media Manager Minimalist Resume.pdf', 'CV_Light_Theme.pdf', 'latest_cv.pdf', 'Tran Viet Hoang_CV.pdf', 'CV ca nhan_Nguyen Cam Ly.pdf', 'CV_ Hoàng Phương Thảo - Thảo Hoàng.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'CV_TRẦN THỊ HẢI YẾN - Hải Yến Trần.pdf', 'HOANG PHUC DUY - CV.pdf', 'NguyenDucThuan_CV.pdf', 'NodeFlair_Resume_BackendNodejs.pdf', 'Resume2024.pdf', 'Thiều Ngọc Mai _CV.pdf', 'CV - Nguyen Minh Quang. - Quang Nguyen Minh.pdf', 'CV Thiên Khôi - Duyên Nguyễn.pdf', 'CV thương mại điện tử - Nguyễn Mai Phương - Nguyen Mai Phuong.pdf', 'CV_PHẠM-VIỆT-HƯNG_-NHÂN-VIÊN-CONTENT-WRITER - Hưng Phạm Việt.pdf', 'CV_Vũ Thu Hiền.pdf', 'CV-Le Nhat Linh.pdf', 'Le-Thi-Hai-Yen-250324.201747 - Yến Lê.pdf', 'Phuong_Anh_Trinh_CV_CinnamonAI.pdf'], 'predict': ['CV_Nguyen_Quang_Hung_DataScientist (4).pdf', 'Cream Black Vintage Typographic Social Media Manager Minimalist Resume.pdf', 'CV-Le Nhat Linh.pdf', 'Le-Thi-Hai-Yen-250324.201747 - Yến Lê.pdf', 'CV_Đức Thành.pdf']}, {'prompt': 'Find 3 candidates who are currently studying or graduated from University of Enonomics and Law', 'answer': ['Vu Lan Anh_CV.pdf', 'Business Analyst - Võ Ngọc Tường Vy.pdf', 'Resume - Nguyen Dang.pdf'], 'predict': ['Vu Lan Anh_CV.pdf']}, {'prompt': 'Find 8 candidates who are currently studying or graduated from Ha Noi Open University or Ho Chi Minh Open University', 'answer': ['Cv_ LucHuynhTanHoang.pdf', 'CV_Internship_Software_Developer_PhamHoangAn.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'CV Cap Tan Dat - Fresher Flutter Developer.pdf', 'CV_Le_Nha_Trang.pdf', 'CV Nguy_n Th_ L_ Xuân - Nhân Viên K_ Toán.pdf', 'Nguyen-Thi-Van-Anh (1).pdf', 'CV xin vi_c ch_nh s_a m_i nh_t.pdf'], 'predict': ['Cv_ LucHuynhTanHoang (1).pdf', 'Cv_ LucHuynhTanHoang.pdf', 'CV_Internship_Software_Developer_PhamHoangAn.pdf', 'CV xin vi_c ch_nh s_a m_i nh_t.pdf', 'Bui Tien Phat resume (1) (1).pdf', 'InternFrontEnd_HoDucPhap.pdf']}, {'prompt': 'Find 3 candidates who are currently studying or graduated from Ho Chi Minh University of Technology', 'answer': ['CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'ITSupport.CV.pdf'], 'predict': ['CV_Ngo_Hung_Thinh.pdf', 'CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'InternFrontEnd_HoDucPhap.pdf']}, {'prompt': 'Find 2 candidates who are currently studying or graduated from University of Enonomics and Law', 'answer': ['CV_TranMinhAnhTruc_Python_Odoo_Developer.pdf', 'ITSupport.CV.pdf'], 'predict': ['Vu Lan Anh_CV.pdf', 'CV_Nguyen_Quang_Hung_DataScientist (4).pdf']}, {'prompt': 'Find 3 candidates who are currently studying or graduated from HCMC University of Foreign Languages - Information Technology', 'answer': ['CV NGUYỄN MAI Duy Phát  - CV IT-TopCV.vn (2).pdf', 'CV_V01 - Thy Volan.pdf', 'NguyenTriDan_AI Engineering Intern_CV.pdf'], 'predict': ['CV NGUYỄN MAI Duy Phát  - CV IT-TopCV.vn (2).pdf', 'NguyenTriDan_AI Engineering Intern_CV.pdf', 'NCV - Intern BE.pdf']}, {'prompt': 'Find 4 applications for Bussiness Analyst position for SKT Telecom', 'answer': ['Cv_ LucHuynhTanHoang.pdf', 'CV_Hoang_Le_Minh__BA.pdf', 'Nhan_Nguyen_Resume_Updated.pdf'], 'predict': ['Cv_ LucHuynhTanHoang.pdf', 'Business Analyst - Võ Ngọc Tường Vy.pdf', 'Quách Thụy Kim Ngân -- Nhân viên thu mua.pdf', 'CV_Nguyen Sy Anh Tuan.pdf']}, {'prompt': 'Find 4 applications for Consultant position for Deloitte', 'answer': ['CV  Phạm Thị Loan - CV2-TopCV.vn - Loan Phạm Thị.pdf', 'Anh Tran - CV 2024.pdf', 'CV Truong Nguyen Thach.pdf', 'CV xin vi_c ch_nh s_a m_i nh_t.pdf'], 'predict': ['CV - Lý V_nh H_ng 2024.pdf', 'CV Content Creator.pdf', 'CV Truong Nguyen Thach.pdf', 'Nguyen-Minh-Duc-TopCV.vn-180524.133945.pdf']}, {'prompt': 'Find 2 candidates who are currently studying or graduated from Ho Chi Minh City University of Food Industry', 'answer': ['HCM_Intern Tester.pdf', 'Jen_150524.pdf'], 'predict': ['Jen_150524.pdf']}, {'prompt': 'Find 8 candidates who are currently studying or graduated from University of Enonomics, Ho Chi Minh University', 'answer': ['CV_SonBao_DS.pdf', 'Nguyễn Như Hương CV.pdf', 'LTT.pdf', 'Anh Tran - CV 2024.pdf', 'CV Truong Nguyen Thach.pdf', 'CV Marketing Executive - Le Thi Thuy Trang.pdf', 'Digital Marketing Resume-Nguyen Thanh Tuyen.pdf', 'Quách Thụy Kim Ngân -- Nhân viên thu mua.pdf'], 'predict': ['Quách Thụy Kim Ngân -- Nhân viên thu mua.pdf']}, {'prompt': 'Find 9 candidates who are currently studying or graduated from either Hanoi University of Science and Technology, VNU University of Engineering and Technology or Posts and Telecommunications Institute of Technology', 'answer': ['1685351692698.pdf', '1705460581859.pdf', '1706358876276.pdf', 'CV_Hoang_Le_Minh__BA.pdf', 'TranPhiHungResume.pdf', 'PhamTienSon_Resume.pdf', 'Nghia_TTS.pdf', 'Trần Tuấn Anh - CV_Embedded Fresher (1).pdf', 'CV TRAN TUAN KIET - NodeJs-TopCV.vn (2).pdf'], 'predict': []}]\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = 0\n",
    "precision = 0\n",
    "long_recall = 0\n",
    "long_precision = 0\n",
    "len_long = 0\n",
    "short_recall = 0\n",
    "short_precision = 0\n",
    "len_short = 0\n",
    "\n",
    "for answer in answers:\n",
    "    num_ans = len(answer['answer'])\n",
    "    correct = 0\n",
    "    ans = set(answer['answer'])\n",
    "    if len(ans) == 0:\n",
    "        print(\"Err\",answer)\n",
    "    for p in answer['predict']:\n",
    "        if p in ans:\n",
    "            correct += 1\n",
    "    recall += correct / num_ans\n",
    "    precision += correct / (len(answer['predict'])+1e-5)\n",
    "    if num_ans > 7:\n",
    "        long_recall += correct / num_ans\n",
    "        long_precision += correct / (len(answer['predict'])+1e-5)\n",
    "        len_long+= 1\n",
    "    else:\n",
    "        short_recall += correct / num_ans\n",
    "        short_precision += correct / (len(answer['predict'])+1e-5)\n",
    "        len_short += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall /= len(answers)\n",
    "precision /= len(answers)\n",
    "long_recall /= len_long\n",
    "long_precision /= len_long\n",
    "short_recall /= len_short\n",
    "short_precision /= len_short\n",
    "f1 = 2 * recall * precision / (recall + precision)\n",
    "short_f1 = 2 * short_recall * short_precision / (short_recall + short_precision)\n",
    "long_f1 = 2 * long_recall * long_precision / (long_recall + long_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.2608948458948459\n",
      "Precision: 0.3576906083455737\n",
      "F1: 0.30171946495878155\n",
      "=====================================\n",
      "Short Recall: 0.27096774193548384\n",
      "Short Precision: 0.31666502841687894\n",
      "Short F1: 0.2920395594976964\n",
      "=====================================\n",
      "Long Recall: 0.22186237373737372\n",
      "Long Precision: 0.5166647305692655\n",
      "Long F1: 0.3104245270946311\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "print(f\"Short Recall: {short_recall}\")\n",
    "print(f\"Short Precision: {short_precision}\")\n",
    "print(f\"Short F1: {short_f1}\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "print(f\"Long Recall: {long_recall}\")\n",
    "print(f\"Long Precision: {long_precision}\")\n",
    "print(f\"Long F1: {long_f1}\")\n",
    "print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haiku\n",
    "\n",
    "Recall: 0.3510887260887261 \\\n",
    "Precision: 0.3828438125961463 \\\n",
    "F1: 0.36627929508666834\n",
    "\n",
    "=====================================\n",
    "\n",
    "Short Recall: 0.3890937019969279 \\\n",
    "Short Precision: 0.38102795277133 \\\n",
    "Short F1: 0.3850185896998829 \\\n",
    "\n",
    "=====================================\n",
    "\n",
    "Long Recall: 0.20381944444444444 \\\n",
    "Long Precision: 0.3898802694173093 \\\n",
    "Long F1: 0.2676948566998643 \\\n",
    "\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3 8b\n",
    "\n",
    "Recall: 0.3098719798719799 \\\n",
    "Precision: 0.3294436310402031 \\\n",
    "F1: 0.3193582276553054\n",
    "\n",
    "=====================================\n",
    "\n",
    "Short Recall: 0.2930875576036866 \\\n",
    "Short Precision: 0.3172799484740911 \\\n",
    "Short F1: 0.3047043109239347\n",
    "\n",
    "=====================================\n",
    "\n",
    "Long Recall: 0.37491161616161617 \\\n",
    "Long Precision: 0.3765779009838872 \\\n",
    "Long F1: 0.3757429112381944\n",
    "\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-3-small\n",
    "Recall: 0.2710502460502461 \\\n",
    "Precision: 0.36965641133703153 \\\n",
    "F1: 0.31276547571875735\n",
    "\n",
    "=====================================\n",
    "\n",
    "Short Recall: 0.2629032258064516 \\\n",
    "Short Precision: 0.3086005324490866 \\\n",
    "Short F1: 0.2839249061602026\n",
    "\n",
    "=====================================\n",
    "\n",
    "Long Recall: 0.3026199494949495 \\\n",
    "Long Precision: 0.6062479420278181 \\\n",
    "Long F1: 0.40371702710388807\n",
    "\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral 7B\n",
    "\n",
    "Recall: 0.2850027750027751 \\\n",
    "Precision: 0.4032058488291777 \\\n",
    "F1: 0.33395334447806935\n",
    "\n",
    "=====================================\n",
    "\n",
    "Short Recall: 0.2936251920122888 \\\n",
    "Short Precision: 0.4151281094206125 \\\n",
    "Short F1: 0.34396191338197385\n",
    "\n",
    "=====================================\n",
    "\n",
    "Long Recall: 0.2515909090909091 \\\n",
    "Long Precision: 0.35700708903736783 \\\n",
    "Long F1: 0.2951693510627643\n",
    "\n",
    "====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3 70b aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini \n",
    "Recall: 0.36257224257224263 \\\n",
    "Precision: 0.360434545384675 \\\n",
    "F1: 0.3615002337389273\n",
    "\n",
    "=====================================\n",
    "\n",
    "Short Recall: 0.33348694316436256 \\\n",
    "Short Precision: 0.3307977101147777 \\\n",
    "Short F1: 0.33213688320928825\n",
    "\n",
    "=====================================\n",
    "\n",
    "Long Recall: 0.4752777777777778 \\\n",
    "Long Precision: 0.4752772820555267 \\\n",
    "Long F1: 0.475277529916523\n",
    "\n",
    "====================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
